{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n\n**Import all the required packages**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport matplotlib\nmatplotlib.use('Agg')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split \nfrom keras.layers import Input, Embedding, Flatten, Dot, Dense\nfrom keras.models import Model\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Extraction**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"books = pd.read_csv(\"../input/goodbooks-10k/books.csv\")\nratings = pd.read_csv(\"../input/goodbooks-10k/ratings.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Exploration**"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"books.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"books.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unique Users and Books**"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_users = ratings.user_id.unique()\nunique_books = ratings.book_id.unique()\nprint(unique_users)\nprint(unique_books)\nn_users=len(unique_users)\nn_books=len(unique_books)\nprint(\"number of unique users: \",n_users)\nprint(\"number of unique books: \",n_books)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\ndata = ratings['rating'].value_counts().sort_index(ascending=False)\ntrace = go.Bar(x = data.index,\n               text = ['{:.1f} %'.format(val) for val in (data.values / ratings.shape[0] * 100)],\n               textposition = 'auto',\n               textfont = dict(color = '#000000'),\n               y = data.values,\n               )\n# Create layout\nlayout = dict(title = 'Distribution Of {} book-ratings'.format(ratings.shape[0]),\n              xaxis = dict(title = 'Rating'),\n              yaxis = dict(title = 'Count'))\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**combining the two Datasets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_data=pd.merge(ratings,books,on=\"book_id\")\ncombined_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Heavily Rated Books**"},{"metadata":{"trusted":true},"cell_type":"code","source":"heavily_rated_books=pd.DataFrame(combined_data.groupby('book_id')['rating'].mean())\nheavily_rated_books['total_ratings']=pd.DataFrame(combined_data.groupby('book_id')['rating'].count())\nheavily_rated_books.sort_values('total_ratings',ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Highly rated Books**"},{"metadata":{"trusted":true},"cell_type":"code","source":"heavily_rated_books.sort_values('rating',ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shilling attacks detection**"},{"metadata":{"trusted":true},"cell_type":"code","source":"book_data={}\nfor id in unique_books:\n    book_data[id]=[0,0]\nfor x in ratings.index:\n    id=ratings['book_id'][x]\n    book_data[id][1]+=1\n    book_data[id][0]+=ratings['rating'][x]\n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_deviation={}\nrating_dict={}\nfor id in unique_users:\n    user_deviation[id]=[0,0]\n    rating_dict[id]=[]\nfor x in ratings.index:\n    user_id=ratings['user_id'][x]\n    book_id=ratings['book_id'][x]\n    rating=ratings['rating'][x]\n    rating_dict[user_id].append(rating)\n    user_deviation[user_id][0]+=(abs(rating-(book_data[book_id][0]))/book_data[book_id][1])/book_data[book_id][1]\n    user_deviation[user_id][1]+=1\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rdma={}\nstandard_deviation={}\navg_rdma=0\nfor user_id in user_deviation.keys():\n    val=user_deviation[user_id][0]/user_deviation[user_id][1]\n    avg_rdma+=val\n    rdma[user_id]=val\n    standard_deviation[user_id]=np.std(rating_dict[user_id])\navg_rdma/=n_users\nprint(avg_rdma)\nprint(standard_deviation)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def f(x):\n    p=10*(x-avg_rdma)/(1-avg_rdma)\n    y=np.exp(p)\n    m=np.exp(10)\n    return (y-1)/(m-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_users","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shilling_attackers=[]\nf_x=[]\nfor user_id in unique_users:\n    x=rdma[user_id]\n    if x>avg_rdma:\n        p=f(x)\n        f_x.append(p)\n        if p>0.5:\n           shilling_attackers.append(user_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max([user_deviation[x][1] for x in unique_users ])\nratings.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for user_id in unique_users:\n    if(standard_deviation[user_id]<0.00000001 and user_deviation[user_id][1]>100):\n         shilling_attackers.append(user_id)\nlen(shilling_attackers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings.shape\nshilling_attackers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_without_shilling_attackers = ratings\nfor ind in ratings_without_shilling_attackers.index:\n    if(ratings_without_shilling_attackers['user_id'][ind] in shilling_attackers):\n        ratings_without_shilling_attackers=ratings_without_shilling_attackers.drop(ind,axis=0)\nratings_without_shilling_attackers.head()        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**building neural network structure**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_without_shilling_attackers.shape\nratings_without_shilling_attackers=ratings_without_shilling_attackers.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Embedding, Flatten, Dot, Dense\nfrom keras.models import Model\nbook_input = Input(shape=[1], name=\"Book-Input\")\nbook_embedding = Embedding(n_books+1, 5, name=\"Book-Embedding\")(book_input)\nbook_vec = Flatten(name=\"Flatten-Books\")(book_embedding)\nuser_input = Input(shape=[1], name=\"User-Input\")\nuser_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\nuser_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\nprod = Dot(name=\"Dot-Product\", axes=1)([book_vec, user_vec])\nmodel_with_shilling_attackers = Model([user_input, book_input], prod)\nmodel_with_shilling_attackers.compile('adam', 'mean_squared_error')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"book_input1 = Input(shape=[1], name=\"Book-Input1\")\nbook_embedding1 = Embedding(n_books+1, 5, name=\"Book-Embedding1\")(book_input1)\nbook_vec1 = Flatten(name=\"Flatten-Books1\")(book_embedding1)\nuser_input1 = Input(shape=[1], name=\"User-Input1\")\nuser_embedding1 = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input1)\nuser_vec1 = Flatten(name=\"Flatten-Users\")(user_embedding1)\nprod1 = Dot(name=\"Dot-Product\", axes=1)([book_vec1, user_vec1])\nmodel_without_shilling_attackers = Model([user_input1, book_input1], prod1)\nmodel_without_shilling_attackers.compile('adam', 'mean_squared_error')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_with_shilling_attackers.fit([ratings.user_id, ratings.book_id], ratings.rating, epochs=10, verbose=1)\nmodel_with_shilling_attackers.save('regression_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_without_shilling_attackers.fit([ratings_without_shilling_attackers.user_id, ratings_without_shilling_attackers.book_id], ratings_without_shilling_attackers.rating, epochs=10, verbose=1)\nmodel_without_shilling_attackers.save('regression_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recommendations(user_id):\n    book_data1 = np.array(list(set(ratings.book_id)))\n    user = np.array([user_id for i in range(len(book_data1))])\n    if(user_id in shilling_attackers):\n        predictions = model_with_shilling_attackers.predict([user, book_data1])\n    else:\n        predictions = model_without_shilling_attackers.predict([user, book_data1])\n    predictions = np.array([a[0] for a in predictions])\n    recommended_book_ids = (-predictions).argsort()[:10]\n    return recommended_book_ids\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_array=[]\nfor user_id in unique_users[:20]:\n    predictions_array.append(list(recommendations(user_id)))\npredictions_array    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bookembeddings = model_with_shilling_attackers.get_layer('Book-Embedding')\nbookembeddings_weights = bookembeddings.get_weights()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport seaborn as sns\npca = PCA(n_components=2)\npca_transformed_result = pca.fit_transform(bookembeddings_weights)\nsns.scatterplot(x=pca_transformed_result[:,0], y=pca_transformed_result[:,1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}